{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robust estimation of Tully-Fisher extragalactic distance errors in NED-D\n",
    "\n",
    "Companion notebook for the \"Predicting extragalactic distance errors using bayesian inference in multi measurement catalogues\" paper, Monthly Notices of the Royal Astronomical Society, Volume 485, Issue 3, May 2019, Pages 4343–4358, https://doi.org/10.1093/mnras/stz615\n",
    "\n",
    "This notebook shows:\n",
    "\n",
    "- A bootstrap robust estimation of TFR distance errors (H,M) and frequentist distance errors (P,Q)\n",
    "\n",
    "The following notebook is [here](bayesian_models.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "wget https://github.com/saint-germain/anisotropias/raw/master/NED28.10.1-D-15.1.0-20181130.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_std(values, weights):\n",
    "    \"\"\"\n",
    "    Return the weighted average and standard deviation.\n",
    "    Richard M. Brugger, \"A Note on Unbiased Estimation of the Standard Deviation\", The American Statistician (23) 4 p. 32 (1969)\n",
    "\n",
    "    values, weights -- Numpy ndarrays with the same shape.\n",
    "    \"\"\"\n",
    "    n=len(values)\n",
    "    average = np.average(values, weights=weights)\n",
    "    variance = (n/(n-1.5))*np.average((values-average)**2, weights=weights)  # Fast and numerically precise\n",
    "    return np.sqrt(variance),average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"NED28.10.1-D-15.1.0-20181130.csv\",skiprows=12)\n",
    "df=df[np.isnan(df['redshift (z)'])] # only measurements without redshift data are useful here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectdata_lite(mymethod,df):\n",
    "    dfa=df[~np.isfinite(df.err)|(df.err==0)] # database of non reported errors\n",
    "    df1=df[np.isfinite(df.err)] # remove measurements that do not report an error\n",
    "    df1=df1[df1.err!=0] # remove measurements that report an error as zero ¬¬\n",
    "# Select a method for analysis\n",
    "    filter=np.full(len(df1), False, dtype=bool)\n",
    "    for mym in mymethod:\n",
    "        filter|=(df1.Method==mym) # choose  methods\n",
    "    df1=df1[filter] \n",
    "    namelist=list(df1['Galaxy ID']) # list of galaxies\n",
    "    counter=collections.Counter(namelist) # count measurements per galaxy\n",
    "# Select galaxies with a minimum number of measurements\n",
    "    ulist=[]\n",
    "    ulist2=[]\n",
    "    nmeas=1\n",
    "    for i in counter.keys():\n",
    "        if counter[i]>nmeas:\n",
    "            ulist+=[i] # all galaxies with more than n_meas measurements\n",
    "        if counter[i]>=1:\n",
    "            ulist2+=[i] # all galaxies with at least one measurement w/a reported error\n",
    "    print('No. of Galaxies with reported errors is %i' % len(ulist2) )\n",
    "    print('No. of Galaxies with more than %i measurements is %i' % (nmeas,len(ulist)) )\n",
    "# Create database for bootstrap, remove unnecessary columns\n",
    "    dfs=df1[np.in1d(df1['Galaxy ID'],ulist)] # dataframe with galaxies with more than nmeas measurements\n",
    "    colu=list(df.columns)\n",
    "    for i in ['Galaxy ID', 'm-M', 'err', 'D (Mpc)']:\n",
    "        colu.remove(i)\n",
    "    dfs.drop(colu, inplace=True, axis=1)\n",
    "# Create database for non-reported errors\n",
    "    filter=np.full(len(dfa), False, dtype=bool)\n",
    "    for mym in mymethod:\n",
    "        filter|=(dfa.Method==mym) # choose  methods\n",
    "    df1a=dfa[filter] \n",
    "    elist=list(np.unique(df1a['Galaxy ID'])) # list of galaxies with measurements without reported errors\n",
    "    filtr=~np.in1d(elist,ulist2) # select only galaxies with no additional measurements using the same method\n",
    "    nulista=np.asarray(elist)[filtr] # list of galaxies without reported errors\n",
    "    print('No. of Galaxies without reported errors is %i' % len(nulista) )\n",
    "    return ulist,dfs,nulista,df1a,len(nulista),len(ulist),len(ulist2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Galaxies with reported errors is 11408\n",
      "No. of Galaxies with more than 1 measurements is 9114\n",
      "No. of Galaxies without reported errors is 884\n"
     ]
    }
   ],
   "source": [
    "mymethod=['Tully-Fisher','Comp. Secondary: Tully-Fisher']\n",
    "ulist,dfs,nulista,odf,*mma=selectdata_lite(mymethod,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "odf=odf[np.in1d(odf['Galaxy ID'], nulista)]\n",
    "odf.to_csv(\"unreportedTF.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only recalculate the following if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "np.random.seed(10)\n",
    "nbins=10000 # 1e4 -> 4 minutes\n",
    "em=[] # number of measurements per galaxy\n",
    "bootp50=[] # mean error from the bootstrap for each galaxy - H error\n",
    "bootmsig=[] # variance of M error\n",
    "bootmother=[] # mad-variance of M error\n",
    "bootsig=[] # variance of H error\n",
    "dboot=[] # mean bootstrap distance\n",
    "bootmad=[] # median absolute deviation - M error\n",
    "wsnt=[] # error propagated from the weighted standard deviation of the distance modulus \n",
    "dwa=[] # distance using weighted average of modulus and err (for show mostly)\n",
    "ecf=[] # propagated (cosmicflows) error - P error\n",
    "eqd=[] # quadrature sum of P error and weighted stdev - Q error\n",
    "for i in ulist:\n",
    "    dfilter=np.in1d(dfs['Galaxy ID'],i)\n",
    "    dummy=dfs[dfilter]\n",
    "    em+=[len(dummy)] # n_meas, number of measurements per galaxy\n",
    "    tli=[]\n",
    "    for km,ke in zip(dummy['m-M'],dummy['err']):\n",
    "        tli+=[list(10**(np.random.normal(km,ke,nbins)/5.+1))] # bootstrap draw for each gal\n",
    "    tli=np.array(tli)\n",
    "    booterr=(np.percentile(tli, 84,axis=0)-np.percentile(tli, 16,axis=0))/2 # sigma draws from bootstrap for each gal\n",
    "    bootmean=np.median(tli,axis=0) # mean draws from bootstrap for each gal\n",
    "############## This block should run for 10k draws ###############\n",
    "#    mymed=np.median(tli,axis=0) #median for error of m error\n",
    "#    mst=[np.median(np.abs(tli[:,kk]-mymed[kk])) for kk in range(nbins)]\n",
    "#    bootmsig+=[(np.percentile(mst, 84,axis=0)-np.percentile(mst, 16,axis=0))/2e6] # error of m error\n",
    "#    bootmother+=[np.median(mst)/1e6]\n",
    "###################################################################\n",
    "    bootp50+=[np.median(booterr)/1e6] \n",
    "    bootsig+=[((np.percentile(booterr, 84)-np.percentile(booterr, 16)))/2e6] \n",
    "    bootmad+=[np.median(np.abs(tli - np.median(tli)))/1e6]\n",
    "    dboot+=[np.median(bootmean)/1e6] \n",
    "    wnat,avnat = weighted_std(dummy['m-M'],1/dummy['err']**2)\n",
    "    distwav=10**(avnat/5+1)/1e6\n",
    "    dwa+=[distwav] #\n",
    "    wsti=0.461*distwav*wnat # propagated weighted standard deviation\n",
    "    wsnt+=[wsti] \n",
    "    ecfi=0.461*distwav/np.sqrt((1/dummy['err']**2).sum()) \n",
    "    ecf+=[ecfi]\n",
    "    eqd+=[np.sqrt(ecfi**2+wsti**2)]    \n",
    "# weighted std using D and propagated err is similar to propagated D error using weighted std on modulus and error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do not re-write bootstrap results by executing the next couple of cells. For emergencies only!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'names': ulist, 'meas': em, 'bootp50':bootp50, 'bootsig':bootsig,'dboot':dboot,'wsnt':wsnt,'dwa':dwa,'ecf':ecf,'eqd':eqd,'bootmad':bootmad}\n",
    "dfb = pd.DataFrame(data=d)\n",
    "dfb.to_csv(\"bootstrap_results_2018.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'names': ulist, 'meas': em, 'bootmad':bootmad,'bootmsig':bootmsig,'bootmother':bootmother}\n",
    "dfm = pd.DataFrame(data=d)\n",
    "dfm.to_csv(\"bootstrap_results_wm_2018.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the above are already in an online github repository\n",
    "# https://github.com/saint-germain/anisotropias/raw/master/bootstrap_results_2018.csv\n",
    "# https://github.com/saint-germain/anisotropias/raw/master/bootstrap_results_wm_2018.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
