In our consideration we have adressed all the concerns that the referee has raised, and we have restructured the text in a way that we think will make our goals clearer to any reader. In particular, we moved the discussion on the prediction for Tully-Fisher relation distance errors for the HyperLEDA catalog from the Appendix to the main text, which we think further validates our approach to predicting distance errors. We hope that with the inclusion of new plots, an update of data tables that now include lower and upper limits to distance estimates, and re-writing of a key parts of all sections, the editor and referee can further consider our manuscript for publication. 

- The authors try to infer the uncertainties of a set of measurements without
 quoted error bars from a set of measurements with quoted error bars.  This
 can only reasonably work if there are good arguments why the two sets of
 measurements are otherwise completely identical.  This means that the
 underlying systematics must be identical, and the measurement result itself
 did not influence the decision whether an error bar was quoted in the
 literature or not.  This is central for what the authors aim to do.  However,
 they do not provide any evidence that this is the case for the data sets they
 study.

Answer: The underlying systematics are identical, because we attempt this prediction only for a subset of measurements in NED-D for which the same method for determining distances is used (TFR). Additionally, our error prediction for missing TF errors in HyperLEDA using the NED-D-based model coincide very well with estimated TF errors in HyperLEDA, even though the the NED-D model is completely independent of HyperLEDA. We believe this shows that the model is indeed learning features that are related to systematic errors in the TF method for distance determination. This discussion was relegated to the appendix originally, but because of its importance we moved this discussion to the main body of the manuscript for this corrected version.


- It is evident from Fig. 1 and Fig. 3 that the distance uncertainties from
 model H (at e.g. 200 Mpc) depends on the number of underlying measurements.
 I would like to see how these plots look for N>15 or N>20, similar to what is
 used in the Bayesian linear and quadratic models.  The fact that the error
 bars grow as function of N suggests that individual errors of the distance
 measures are somewhat systematically underestimated.   This point is
 important and must be discussed.  

Answer: Frequentist methods both over- and underestimate errors, as the new Fig. 1 shows (including NED-D data for all distance determination methods). If they were appropriate measures of the scatter, they would coincide better with H/M error trends. This is now made clear in the text. For TF-only NED-D data, the scale of the error (relative error) does not (strongly) depend on the limiting number of measurements. We now include D vs sigma_h and sigma_M plot (Figure 4) which shows that the slope remains similar even for galaxies with a large number of distance measurements. An exception appears for Fig. 4 (left), which shows that when N_TF=2, the H relative error is significantly lower than for a higher threshold. This shows method H's usefulness at estimating errors in a way that is both conservative and realistic.

- If anything, this trend should be the
 opposite (more measurements should increase our knowledge, not decrease it),
 and indicates that results with a small number of measruements N cannot be
 trusted.

Answer: In multi-measurement catalogs such as NED-D, we observe that the scatter of reported distances and reported individual measurement errors do not match in most cases. This situation happens because there are hidden systematic sources. These systematics can not be removed, but they can be margizalized over in order to estimate the true variance of a distance estimation based on multiple measurements. In this case, more measurements can increase our knowledge of systematic uncertainties in distance measurements, which is what we do when we attempt to predict unreported TF errors.

- It appears that the Bayesian quadratic model only works, in terms of the
 Bayesian p-value, if the observations are constrainted to galaxies with N>25
 measurements.  Otherwise the model overfits (p~1) or underfits (p~0) the
 data.  

Answer: The quadratic model works under very limited conditions, and the posterior shows that the random error component is degenerate (and ultimately unnecesary, as the mode/median is close to zero), which is why we decide to use a simpler linear model. The degenerate parameter included in the quadratic model increases the randomness of the error around the expected values of the probability of each galaxy, which is why the linear model works better (i.e. for more galaxies) at not overpredicting the error.

- The same is true for the Bayesian linear model, with other threshold
 values of N.  It is not clear how such a model could be generally useful,
 except for very specific cases.  

Answer: This is true, our model is only useful for predicting missing TF errors within the same distance range as the data points used to inform the model. Incidentally, most galaxies with missing TF errors are within or very near the distance range of the data points used to inform the model, as Figs. 14-15 show. We do not attempt to predict missing distance errors for methods other than TFR, although we think it could be done in the future.

- Why does the model break down?  What happens
 to observations that are not fulfillying this requirement?

Answer: The model works at a (relatively) high threshold N_TF because the Central Limit Theorem implies that "when independent random variables are added, their properly normalized sum tends toward a normal distribution [...] even if the original variables themselves are notnormally distributed". Thus, it is easier to estimate the systematic (true) variance from those measurements than from galaxies with a low number of measurements. Still, one should keep in mind that our predictions are very conservative scenarios for unknown errors (the worst case scenario being having no errors at all).

- It is not clear why it is useful to estimate the variance of the predicted
 measurement uncertainty.  Typically one would be happy with the expected/mean
 uncertainty alone.  What is the variance of the uncertainty good for in
 practice?

Answer: This is shown only to justify the choice of having this variance being proportional to the error(variance \propto sigma_D) in our model. This is now made clear in the text.
 
- It is not clear to me what kind of errors the authors want to predict.  As
 discussed above, the size of the H model error seems to depend on the number
 of TF measurements N.  

Answer: The scale of the error (relative error) for TF distance measurements does not strongly depend on N_TF for NTF>3. As mentioned above, we now include a D vs sigma plot (vs N_measurements) (Figure 4) which shows that the slope remains similar even for galaxies with a large number of distance measurements. 

- This means that the specific models that the authors
 derive (Bayesian linear and quadratic models) only work for observations of
 galaxies with a similar number of N.  It is not clear whether the 818
 galaxies for which they use their results actually fulfill this criterion.
 Furthermore, it is clear that the results cannot be generalized to galaxies
 with a smaller number of distance measurements, which means that the results
 are of limited use.

Answer: It is true that the success of the predictive model depends on N (as mentioned above). However, our prediction is not based on any significant assumption about the (no 884 galaxies since the new 2018 NED-D catalog wa released) galaxies, other than the fact that the distance range changes with N. The galaxies for which the linear model works do not have particular physical properties that make them special, other than having a bias towards closer distances, which we include in our reported prediction (with a black diamond which indicates that the galaxy is outside of the predictive distance range). 


Minor concerns
--------------

- For the 818 galaxies of the NED-D that have TF distances without quoted
 distance errors, it is important know how many measurements (without distance
 errors) were actually done per galaxy.

Answer: About 70% have more than one TF measurement, and 5% have more than 4 measurements. The most TF measurements are 13. However, as mentioned in the answer above, the number of measurements only indicates a working distance range, which we consider in our model. About 80 out of 900 galaxies in NED-D, and 3 out of 203 in HyperLEDA are located outside the model's distance working range. We indicate when predictions are outside of this working range in Figs. 14-15.

- The authors use as starting point for combining potentially discrepant
 distance measures a Gaussian mixture model, giving equal weight to all of the
 measurements (beginning of Section 2).  Model H (median and 1-sigma
 percentiles of that Gaussian mixture model) is the claimed to be the optimal
 or most faithful representation of the associated errors.  In my eyes, these
 are already very specific assumptions, and the authors should comment on the
 validty of these assumptions in context of the observations.

Answer: If the frequentist P and/or Q errors were representative of the uncertainty in distance measurement (as it is commonly asserted, cf. Cosmicflows), they would coincide with the results obtained using the H and/or M methods for error estimation. The fact that in general they differ shows that P/Q errors are insufficiently accurate measurements of the uncertainty in distance measurement.
 
- Given that error bars for the given problem are inherently non-symmetric, I
 do not understand why instead symmetric error bars are chosen for the four
 models.

Answer: We now also report H errors in our data tables in terms of distinct lower and upper limits. M, P, and Q errors are by definition symmetric. We should note, however, that 95 percent of all H errors are less than 15% asymmetric and 95 percent of errors for galaxies with more than 15 measurements are less than 5 Mpc asymmetric. For H errors calculated for the HyperLEDA catalog, 95 percent of all H errors are less than 8% asymmetric and 95 percent of errors for galaxies with more than 2 measurements are less than 6 Mpc asymmetric.

- Fig. 5: It is not clear how the bootstrap realizations were calculated.  Is
 this somehow using the same number of measurements per galaxy that were in
 the original galaxy catalogue?

Answer: Yes, as indicated in Eq.1. The corresponding section was rewritten to better explain way the distribution of D_G is sampled.

- In Fig. 6, I'm wondering whether the p-value is correctly defined.  A larger
 p-value (red points) seem to correspond to more points with a larger
 simulated discrepancy.  This is directly opposite to the definition of the
 Bayesian p-value.

Answer: The goal of this test is to find the lowest threshold at which that the Bayesian p-value is closer to 0.5, which indicates the largest possible number of error data that can be predicted by the model.

- In Fig. 6, larger N correspond to larger p-values, in Fig. 9, larger N
 correspond to smaller p-values.  Does this fit together? 

Answer: As mentioned above, the quadratic model tends to overpredict randomness, whereas the opposite is the case for the linear model.

